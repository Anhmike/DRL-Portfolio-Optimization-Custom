{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Docker Images and Register with ECR\n",
    "This notebook is an extension of the build [CPU](https://github.com/daniel-fudge/sagemaker-tennis/blob/master/build-cpu.ipynb) and [GPU](https://github.com/daniel-fudge/sagemaker-tennis/blob/master/build-gpu.ipynb) notebooks in the related [Tennis](https://github.com/daniel-fudge/sagemaker-tennis) repo. If you are unfamiliar with building Docker images and registering them in AWS [ECR](https://aws.amazon.com/ecr/), please see the [Tennis](https://github.com/daniel-fudge/sagemaker-tennis) repo.\n",
    "\n",
    "If working on your own fork, you may want to set the following.\n",
    "```shell\n",
    "git config --global user.name \"Your Name\"\n",
    "git config --global user.email your.email@domain.com\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ECR Access\n",
    "When you first created an SakeMaker instance either you made or selected a custom role or the system created one for you.  I believe there has been a change in the service since I initially made my `AmazonSageMaker-ExecutionRole`.  To execute the push below I had to add the `AmazonEC2ContainerRegistryFullAccess` policy to my SageMaker [IAM](https://console.aws.amazon.com/iam) role.  Specifically the `ecr:InitiateLayerUpload` access had to be added for images other than the SageMaker images covered in the SageMaker full access policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and register the CPU container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod -R 755 container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting CPU image\n",
      "Login Succeeded\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  3.113MB\n",
      "Step 1/10 : ARG REGION=us-east-1\n",
      "Step 2/10 : FROM 520713654638.dkr.ecr.$REGION.amazonaws.com/sagemaker-pytorch:1.1.0-cpu-py3\n",
      " ---> d374fb352c72\n",
      "Step 3/10 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> b4524ab0cb43\n",
      "Step 4/10 : COPY requirements.txt requirements.txt\n",
      " ---> Using cache\n",
      " ---> d914220df64a\n",
      "Step 5/10 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 3964e488f753\n",
      "Step 6/10 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 2ba02b18656e\n",
      "Step 7/10 : COPY /src /opt/ml/code\n",
      " ---> 2230f88c7b98\n",
      "Step 8/10 : RUN chmod -R 755 /opt/ml/code\n",
      " ---> Running in 177f361da674\n",
      "Removing intermediate container 177f361da674\n",
      " ---> 30aaab1a056f\n",
      "Step 9/10 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in 7c74c23b1ddf\n",
      "Removing intermediate container 7c74c23b1ddf\n",
      " ---> 0fcaf05c7354\n",
      "Step 10/10 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in c42742c80c94\n",
      "Removing intermediate container c42742c80c94\n",
      " ---> 39cd0bedaaf6\n",
      "Successfully built 39cd0bedaaf6\n",
      "Successfully tagged portfolio-optimization-cpu:latest\n",
      "Building CPU image\n",
      "The push refers to repository [031118886020.dkr.ecr.us-east-1.amazonaws.com/portfolio-optimization-cpu]\n",
      "\n",
      "\u001b[1B20fc947e: Preparing \n",
      "\u001b[1B5fc5fc6b: Preparing \n",
      "\u001b[1B31a845ec: Preparing \n",
      "\u001b[1B33237a0d: Preparing \n",
      "\u001b[1B532f8c4c: Preparing \n",
      "\u001b[1Becc4e4d4: Preparing \n",
      "\u001b[1B808cebd3: Preparing \n",
      "\u001b[1Bf05eda79: Preparing \n",
      "\u001b[1B71db9add: Preparing \n",
      "\u001b[1B53464ab3: Preparing \n",
      "\u001b[1Bc4bd5031: Preparing \n",
      "\u001b[1Bd01ff144: Preparing \n",
      "\u001b[1B7f77d9db: Preparing \n",
      "\u001b[1B42719515: Preparing \n",
      "\u001b[1B103e78c9: Preparing \n",
      "\u001b[1Be637fbff: Preparing \n",
      "\u001b[17B0fc947e: Pushed   3.108MB/3.1MB[15A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[16A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[16A\u001b[2K\u001b[4A\u001b[2K\u001b[17A\u001b[2K\u001b[2A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2Klatest: digest: sha256:0327ff8dd740350b92c7c3b2894416b6faded1070a77a3ea68caaea13184ea3a size: 3881\n"
     ]
    }
   ],
   "source": [
    "!./container/build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and register the GPU container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting GPU image\n",
      "Login Succeeded\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  3.113MB\n",
      "Step 1/10 : ARG REGION=us-east-1\n",
      "Step 2/10 : FROM 520713654638.dkr.ecr.$REGION.amazonaws.com/sagemaker-pytorch:1.1.0-gpu-py3\n",
      " ---> adbf113505a2\n",
      "Step 3/10 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 635764385479\n",
      "Step 4/10 : COPY requirements.txt requirements.txt\n",
      " ---> Using cache\n",
      " ---> 9449a77875e9\n",
      "Step 5/10 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 783e15fb6bc1\n",
      "Step 6/10 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 537b2b3c690c\n",
      "Step 7/10 : COPY /src /opt/ml/code\n",
      " ---> 564e210508bd\n",
      "Step 8/10 : RUN chmod -R 755 /opt/ml/code\n",
      " ---> Running in a83b789a20c3\n",
      "Removing intermediate container a83b789a20c3\n",
      " ---> 2b11854bae1d\n",
      "Step 9/10 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in 81d20dd5cebd\n",
      "Removing intermediate container 81d20dd5cebd\n",
      " ---> 3ea337c75bb5\n",
      "Step 10/10 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in 576882bc4738\n",
      "Removing intermediate container 576882bc4738\n",
      " ---> 541cf370aa16\n",
      "Successfully built 541cf370aa16\n",
      "Successfully tagged portfolio-optimization-gpu:latest\n",
      "Building GPU image\n",
      "The push refers to repository [031118886020.dkr.ecr.us-east-1.amazonaws.com/portfolio-optimization-gpu]\n",
      "\n",
      "\u001b[1B3d9e92c2: Preparing \n",
      "\u001b[1Bd766ad41: Preparing \n",
      "\u001b[1B3657abf8: Preparing \n",
      "\u001b[1B33237a0d: Preparing \n",
      "\u001b[1B34a0d5c7: Preparing \n",
      "\u001b[1Bf3470ef5: Preparing \n",
      "\u001b[1B808cebd3: Preparing \n",
      "\u001b[1Ba36844e2: Preparing \n",
      "\u001b[1Bac83281f: Preparing \n",
      "\u001b[1B53464ab3: Preparing \n",
      "\u001b[1B7a178c2c: Preparing \n",
      "\u001b[1B1f16c1bd: Preparing \n",
      "\u001b[1Ba3d32a13: Preparing \n",
      "\u001b[1Bc432fc3d: Preparing \n",
      "\u001b[1Bd718ffb0: Preparing \n",
      "\u001b[1Bf211099a: Preparing \n",
      "\u001b[1Bb5b15f16: Preparing \n",
      "\u001b[1B0239569d: Preparing \n",
      "\u001b[1B42719515: Preparing \n",
      "\u001b[1B103e78c9: Preparing \n",
      "\u001b[1Be637fbff: Preparing \n",
      "\u001b[21B766ad41: Pushed lready exists B[18A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[14A\u001b[2K\u001b[21A\u001b[2K\u001b[12A\u001b[2K\u001b[21A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[2A\u001b[2K\u001b[22A\u001b[2Klatest: digest: sha256:a13d17147be7d07437cd245804e2a74b9305ae903ff0a2e7a1c69945c75c2049 size: 4937\n"
     ]
    }
   ],
   "source": [
    "!./container/build_and_push.sh gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Notebook for local execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user has root access.\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash ./utils/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the CPU model locally\n",
    "Since we only want to check the functionality, we will start at day 2900.  There are only 2922 days worth of signals so we are only letting the model trade for 22 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmp8ot391h8_algo-1-cv4gj_1 ... \n",
      "\u001b[1BAttaching to tmp8ot391h8_algo-1-cv4gj_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m 2020-07-13 01:20:16,269 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m 2020-07-13 01:20:16,273 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m 2020-07-13 01:20:16,286 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m 2020-07-13 01:20:16,287 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m 2020-07-13 01:20:16,288 sagemaker-containers INFO     Module train does not provide a setup.py. \n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m 2020-07-13 01:20:16,288 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m 2020-07-13 01:20:16,288 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m 2020-07-13 01:20:16,289 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m /usr/bin/python -m pip install . \n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Building wheels for collected packages: train\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m   Building wheel for train (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m \u001b[?25h  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=1288651 sha256=865cda26d3ac61c3935db8b5de232fa18268c05e006c855c11d04f33165ddf70\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-7m2eyk94/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Successfully built train\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Installing collected packages: train\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Successfully installed train-1.0.0\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m 2020-07-13 01:20:18,070 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m 2020-07-13 01:20:18,084 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m \n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m \n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"current_host\": \"algo-1-cv4gj\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m         \"algo-1-cv4gj\"\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m         \"start_day\": 2900\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"job_name\": \"portfolio-optimization-cpu-2020-07-13-01-20-13-933\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"master_hostname\": \"algo-1-cv4gj\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m         \"current_host\": \"algo-1-cv4gj\",\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m             \"algo-1-cv4gj\"\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m \n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m \n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_HOSTS=[\"algo-1-cv4gj\"]\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_HPS={\"start_day\":2900}\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-cv4gj\",\"hosts\":[\"algo-1-cv4gj\"]}\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_CURRENT_HOST=algo-1-cv4gj\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-cv4gj\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-cv4gj\"],\"hyperparameters\":{\"start_day\":2900},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"portfolio-optimization-cpu-2020-07-13-01-20-13-933\",\"log_level\":20,\"master_hostname\":\"algo-1-cv4gj\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-cv4gj\",\"hosts\":[\"algo-1-cv4gj\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_USER_ARGS=[\"--start_day\",\"2900\"]\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m SM_HP_START_DAY=2900\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m PYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m \n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m \n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m /usr/bin/python -m train --start_day 2900\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m \n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m \n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m CPU activated.\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Setting up the environment.\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Size of action space: 10\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m State space per agent: 71\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Training the agent.\n",
      "\u001b[36malgo-1-cv4gj_1  |\u001b[0m Beginning initial training.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "start_day = 2900\n",
    "role = get_execution_role()\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='local',\n",
    "                      image_name='portfolio-optimization-cpu:latest',\n",
    "                      hyperparameters={'start_day': start_day})\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locate the ECR image just built and pushed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/portfolio-optimization-cpu:latest'.format(account, region)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='ml.m5.large',\n",
    "                      image_name=ecr_image,\n",
    "                      train_use_spot_instances=True,\n",
    "                      train_max_run=14400,\n",
    "                      train_max_wait=14400,\n",
    "                      hyperparameters={'start_day': start_day})\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "sagemaker_session = Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "job_name = estimator._current_job_name\n",
    "print(bucket)\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy and unpack the result archive\n",
    "Since we didn't start trading until nearly the end, the results are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "key = '{}/output/output.tar.gz'.format(estimator._current_job_name)\n",
    "print(key)\n",
    "s3.Bucket(bucket).download_file(key, 'output.tar.gz')\n",
    "shutil.unpack_archive('output.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='history.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [Tennis Repo](https://github.com/daniel-fudge/sagemaker-tennis)\n",
    "- [Amazon ECS](https://aws.amazon.com/ecs/)\n",
    "\n",
    "#### SageMaker\n",
    "- [SageMaker Example:  Extending PyTorch Container](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/advanced_functionality/pytorch_extending_our_containers)\n",
    "- [How Amazon SageMaker interacts with your Docker container for training](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html)\n",
    "- [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk)\n",
    "- [scikit-bring-your-own](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb)\n",
    "- [SageMaker PyTorch container](https://github.com/aws/sagemaker-pytorch-container)\n",
    "- [SageMaker Instance types](https://aws.amazon.com/sagemaker/pricing/instance-types/)\n",
    "- [SageMaker Instance prices](https://aws.amazon.com/sagemaker/pricing/)\n",
    "\n",
    "#### Docker\n",
    "- [Dockerfile](https://docs.docker.com/engine/reference/builder/)\n",
    "- [Docker home page](http://www.docker.com)\n",
    "- [Getting started with Docker](https://docs.docker.com/get-started/)\n",
    "- [Dockerfile reference](https://docs.docker.com/engine/reference/builder/)\n",
    "- [docker run reference](https://docs.docker.com/engine/reference/run/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
